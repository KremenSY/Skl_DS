{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-smrZewE1tU2"
   },
   "source": [
    "# Урок 6. Многоклассовая классификация.\n",
    "\n",
    "Посмотрим на примере алгоритма логистической регрессии и метода опорных векторов, как работать с различными методами многоклассовой классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5kQdZzo1tU3"
   },
   "source": [
    "### 1.\n",
    "Вспомните датасет Wine. Загрузите его, разделите на тренировочную и тестовую выборки (random_state=17), используя только [9, 11, 12] признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "paB2E5141tU4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LdwwBPqq1tU7"
   },
   "outputs": [],
   "source": [
    "wine_dataset=load_wine()\n",
    "wine_df=pd.DataFrame(data=np.c_[wine_dataset['data'], wine_dataset['target']],\n",
    "                    columns=wine_dataset['feature_names']+['target'])\n",
    "# wine_df['label']=wine_df.target.replace(dict(enumerate(wine_dataset.target_names)))\n",
    "X=np.array(wine_df[['color_intensity','od280/od315_of_diluted_wines', 'proline']])\n",
    "y=np.array(wine_df.iloc[:,13:14])\n",
    "df=wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alcohol    0\n",
      "dtype: int64\n",
      "malic_acid    0\n",
      "dtype: int64\n",
      "ash    0\n",
      "dtype: int64\n",
      "alcalinity_of_ash    0\n",
      "dtype: int64\n",
      "magnesium    0\n",
      "dtype: int64\n",
      "total_phenols    0\n",
      "dtype: int64\n",
      "flavanoids    0\n",
      "dtype: int64\n",
      "nonflavanoid_phenols    0\n",
      "dtype: int64\n",
      "proanthocyanins    0\n",
      "dtype: int64\n",
      "color_intensity    0\n",
      "dtype: int64\n",
      "hue    0\n",
      "dtype: int64\n",
      "od280/od315_of_diluted_wines    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.572193</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.573840</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.593060</td>\n",
       "      <td>0.372014</td>\n",
       "      <td>0.455285</td>\n",
       "      <td>0.970696</td>\n",
       "      <td>0.561341</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571053</td>\n",
       "      <td>0.205534</td>\n",
       "      <td>0.417112</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.575862</td>\n",
       "      <td>0.510549</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.274448</td>\n",
       "      <td>0.264505</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.560526</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>0.700535</td>\n",
       "      <td>0.412371</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.611814</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.757098</td>\n",
       "      <td>0.375427</td>\n",
       "      <td>0.447154</td>\n",
       "      <td>0.695971</td>\n",
       "      <td>0.646933</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.878947</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>0.467391</td>\n",
       "      <td>0.989655</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.558360</td>\n",
       "      <td>0.556314</td>\n",
       "      <td>0.308943</td>\n",
       "      <td>0.798535</td>\n",
       "      <td>0.857347</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581579</td>\n",
       "      <td>0.365613</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>0.536082</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.495781</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.444795</td>\n",
       "      <td>0.259386</td>\n",
       "      <td>0.455285</td>\n",
       "      <td>0.608059</td>\n",
       "      <td>0.325963</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.970356</td>\n",
       "      <td>0.582888</td>\n",
       "      <td>0.510309</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.056962</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.205047</td>\n",
       "      <td>0.547782</td>\n",
       "      <td>0.130081</td>\n",
       "      <td>0.172161</td>\n",
       "      <td>0.329529</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.623684</td>\n",
       "      <td>0.626482</td>\n",
       "      <td>0.598930</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.282759</td>\n",
       "      <td>0.086498</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.513652</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.336662</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.589474</td>\n",
       "      <td>0.699605</td>\n",
       "      <td>0.481283</td>\n",
       "      <td>0.484536</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.210345</td>\n",
       "      <td>0.073840</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.296530</td>\n",
       "      <td>0.761092</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.397290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.563158</td>\n",
       "      <td>0.365613</td>\n",
       "      <td>0.540107</td>\n",
       "      <td>0.484536</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.231034</td>\n",
       "      <td>0.071730</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.331230</td>\n",
       "      <td>0.684300</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.400856</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.664032</td>\n",
       "      <td>0.737968</td>\n",
       "      <td>0.716495</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.368966</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.296530</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.105691</td>\n",
       "      <td>0.120879</td>\n",
       "      <td>0.201141</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
       "0    0.842105    0.191700  0.572193           0.257732   0.619565   \n",
       "1    0.571053    0.205534  0.417112           0.030928   0.326087   \n",
       "2    0.560526    0.320158  0.700535           0.412371   0.336957   \n",
       "3    0.878947    0.239130  0.609626           0.319588   0.467391   \n",
       "4    0.581579    0.365613  0.807487           0.536082   0.521739   \n",
       "..        ...         ...       ...                ...        ...   \n",
       "173  0.705263    0.970356  0.582888           0.510309   0.271739   \n",
       "174  0.623684    0.626482  0.598930           0.639175   0.347826   \n",
       "175  0.589474    0.699605  0.481283           0.484536   0.543478   \n",
       "176  0.563158    0.365613  0.540107           0.484536   0.543478   \n",
       "177  0.815789    0.664032  0.737968           0.716495   0.282609   \n",
       "\n",
       "     total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "0         0.627586    0.573840              0.283019         0.593060   \n",
       "1         0.575862    0.510549              0.245283         0.274448   \n",
       "2         0.627586    0.611814              0.320755         0.757098   \n",
       "3         0.989655    0.664557              0.207547         0.558360   \n",
       "4         0.627586    0.495781              0.490566         0.444795   \n",
       "..             ...         ...                   ...              ...   \n",
       "173       0.241379    0.056962              0.735849         0.205047   \n",
       "174       0.282759    0.086498              0.566038         0.315457   \n",
       "175       0.210345    0.073840              0.566038         0.296530   \n",
       "176       0.231034    0.071730              0.754717         0.331230   \n",
       "177       0.368966    0.088608              0.811321         0.296530   \n",
       "\n",
       "     color_intensity       hue  od280/od315_of_diluted_wines   proline  target  \n",
       "0           0.372014  0.455285                      0.970696  0.561341     0.0  \n",
       "1           0.264505  0.463415                      0.780220  0.550642     0.0  \n",
       "2           0.375427  0.447154                      0.695971  0.646933     0.0  \n",
       "3           0.556314  0.308943                      0.798535  0.857347     0.0  \n",
       "4           0.259386  0.455285                      0.608059  0.325963     0.0  \n",
       "..               ...       ...                           ...       ...     ...  \n",
       "173         0.547782  0.130081                      0.172161  0.329529     1.0  \n",
       "174         0.513652  0.178862                      0.106227  0.336662     1.0  \n",
       "175         0.761092  0.089431                      0.106227  0.397290     1.0  \n",
       "176         0.684300  0.097561                      0.128205  0.400856     1.0  \n",
       "177         0.675768  0.105691                      0.120879  0.201141     1.0  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print(df.iloc[:,i:i+1].isnull().sum())\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(df)\n",
    "df_scaled=pd.DataFrame(data_scaled, columns=df.columns)\n",
    "df=df_scaled      \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMLiMOUr1tU9"
   },
   "source": [
    "**Задайте тип кросс-валидации с помощью StratifiedKFold: 5-кратная, random_state=17.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OTY-C4me1tU-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LOVHhQ921tVA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=17, shuffle=True)\n",
    "skf.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2ClbxRe1tVC"
   },
   "source": [
    "### 2.\n",
    "Обучите логистическую регрессию (LogisticRegression) с параметром C по умолчанию и random_state=17. Укажите гиперпараметр multi_class='ovr' - по умолчанию многие классификаторы используют именно его. С помощью cross_val_score сделайте кросс-валидацию (используйте объект skf) и выведите среднюю долю правильных ответов на ней (используйте функцию mean). Отдельно выведите долю правильных ответов на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CJhpcgqc1tVJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 0. 2. 1. 0. 1. 2. 0. 2. 0. 1. 1. 2. 2. 2. 1. 1. 1. 1. 1. 0. 2.\n",
      " 1. 1. 0. 1. 2. 1. 2. 1. 0. 0. 2. 1. 0. 1. 1. 1. 2. 1. 1. 2. 2.]\n",
      "[1.         1.         0.86666667]\n",
      "0.9555555555555556\n",
      "0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "y=y.ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=17)\n",
    "\n",
    "clf_lr = LogisticRegression(random_state=17, max_iter=10000, multi_class='ovr')\n",
    "model_lr=clf_lr.fit(X_train, y_train)\n",
    "y_predicted_lr=clf_lr.predict(X_test)\n",
    "print(y_predicted_lr)\n",
    "cvs_lr=cross_val_score(clf_lr, X_test, y_test, cv=3)\n",
    "print(cvs_lr)\n",
    "print(cvs_lr.mean())\n",
    "print(model_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2JoC3fB1tVM"
   },
   "source": [
    "### 3.\n",
    "Обучите метод опорных векторов (SVC) с random_state=17 и остальными параметрами по умолчанию. Этот метод при мультиклассовой классификации также использует метод \"ovr\". Сделайте кросс-валидацию (используйте skf) и, как и в предыдущем пункте, выведите среднюю долю правильных ответов на ней. Отдельно выведите долю правильных ответов на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "50kaD7MQ1tVN"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3DCvlNRd1tVR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 0. 2. 2. 0. 1. 2. 0. 2. 0. 1. 1. 2. 2. 2. 1. 1. 1. 1. 1. 0. 2.\n",
      " 1. 1. 0. 1. 2. 1. 2. 2. 0. 0. 2. 1. 0. 1. 1. 1. 2. 1. 1. 2. 2.]\n",
      "[1.         1.         0.93333333]\n",
      "0.9777777777777779\n",
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf_SVC = make_pipeline(StandardScaler(), SVC(gamma='auto', random_state=17))\n",
    "model_SVC=clf_SVC.fit(X_train, y_train)\n",
    "y_predicted_SVC=clf_SVC.predict(X_test)\n",
    "print(y_predicted_SVC)\n",
    "cvs_SVC=cross_val_score(clf_SVC, X_test, y_test, cv=3)\n",
    "print(cvs_SVC)\n",
    "print(cvs_SVC.mean())\n",
    "print(model_SVC.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMvjv6pR1tVX"
   },
   "source": [
    "Как видно из полученной метрики, на тестовой выборке метод с гиперпараметрами по умолчанию работает явно намного хуже логистической регрессии. В целом, SVM достаточно плохо масштабируется на размер обучающего набора данных (как видно, даже с тремя признаками он работает не очень хорошо), но благодаря возможности выбора различных ядер (функций близости, которые помогают разделять данные) и другим гиперпараметрам SVM можно достаточно точно настроить под определенный вид данных. Подробнее на этом останавливаться в контексте данного урока не будем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LqZbdk31tVY"
   },
   "source": [
    "### 4.\n",
    "Для предсказаний обеих моделей постройте матрицу ошибок (confusion matrix) и напишите, какие классы каждая из моделей путает больше всего между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5dRSK--u1tVY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VkXUKkhp1tVb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  0  0]\n",
      " [ 0 19  0]\n",
      " [ 0  4 13]]\n",
      "[[ 9  0  0]\n",
      " [ 0 19  0]\n",
      " [ 0  2 15]]\n"
     ]
    }
   ],
   "source": [
    "conf_mtrx_lr = confusion_matrix(y_test, y_predicted_lr)\n",
    "print(conf_mtrx_lr)\n",
    "conf_mtrx_SVC = confusion_matrix(y_test, y_predicted_SVC)\n",
    "print(conf_mtrx_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqW8if321tVd"
   },
   "source": [
    "### 5.\n",
    "Для каждой модели выведите classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iuu7neuS1tVe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00         9\n",
      "     class_1       0.83      1.00      0.90        19\n",
      "     class_2       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.94      0.92      0.92        45\n",
      "weighted avg       0.93      0.91      0.91        45\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00         9\n",
      "     class_1       0.90      1.00      0.95        19\n",
      "     class_2       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.97      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = wine_dataset.target_names #['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_test, y_predicted_lr, target_names=target_names))\n",
    "print(classification_report(y_test, y_predicted_SVC, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework_classification-2_les-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
