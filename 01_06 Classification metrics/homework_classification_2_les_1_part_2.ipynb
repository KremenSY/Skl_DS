{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0RpWMuyhXNc"
   },
   "source": [
    "# –£—Ä–æ–∫ 4. –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —á.2\n",
    "\n",
    "–ü—Ä–æ–¥–æ–ª–∂–∏–º —Ä–∞–±–æ—Ç—É —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –í –ø—Ä–µ–¥—ã–¥—É—â–µ–º –∑–∞–¥–∞–Ω–∏–∏ –º—ã —Ä–∞–∑–æ–±—Ä–∞–ª–∏ –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫ –∏ –¥–≤–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø—Ä–∏ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n",
    "\n",
    "–°–µ–π—á–∞—Å —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º F-–º–µ—Ä—É - —Å–æ–≤–æ–∫—É–ø–Ω—É—é –º–µ—Ç—Ä–∏–∫—É –ø–æ precision –∏ recall - –∏ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—É—é AUC-ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "desLnfjBhXNe"
   },
   "source": [
    "### 2.1\n",
    "–ò–∑ –∑–∞–¥–∞–Ω–∏—è –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É —É—Ä–æ–∫—É –≤—ã–±–µ—Ä–∏—Ç–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä, –∫–æ—Ç–æ—Ä—ã–π –¥–∞–≤–∞–ª –Ω–∞–∏–º–µ–Ω—å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ recall, –≤—ã—á–∏—Å–ª–∏—Ç–µ –¥–ª—è –Ω–µ–≥–æ precision, –ø—Ä–∏–º–µ–Ω–∏–≤ precision_score, –∏ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –ø–æ—Å—á–∏—Ç–∞–π—Ç–µ F1-–º–µ—Ä—É (—Ä–∞—Å—á–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å). –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –æ—Ç–≤–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é.\n",
    "\n",
    "–°—Ä–∞–≤–Ω–∏—Ç–µ –ø–æ–ª—É—á–µ–Ω–Ω—É—é f1-–º–µ—Ä—É —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º —Å—Ä–µ–¥–Ω–µ–≥–æ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–ª–Ω–æ—Ç—ã –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP(True positive), TN (True negative), FP (False positive), FN (False negtive)\n",
    "# Accuracy=(TP+TN)/(TP+FP+FN+TN)\n",
    "# Precision=TP/(TP+FP)\n",
    "# Recall=TP/TP+FN\n",
    "# Arithmetic mean=(Precission+Recall)/2\n",
    "# F-measure (Harmonic mean)=(1+b*b)*(precission*recall)/(b*b*precission+recall)\n",
    "# AUC-ROC - Area Under Curve(Receiver Operating Characteristic curve) \n",
    "# # in coordinates of x=ùêπùëÉùëÖ (false posotove rate) =ùêπùëÉ/(ùêπùëÉ+ùëáùëÅ) and ùëáùëÉùëÖ (true positive rate) =ùëáùëÉ/(ùëáùëÉ+ùêπùëÅ)\n",
    "# # in range from 0.5 (worst) to 1 (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PqBv_cQmhXNf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7inF9IHdhXNl"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex       Age  SibSp     Parch      Fare  Embarked\n",
       "0         0.0     1.0  0.0  0.271174  0.125  0.000000  0.014151       0.2\n",
       "1         1.0     0.0  1.0  0.472229  0.125  0.000000  0.139136       1.0\n",
       "2         1.0     1.0  1.0  0.321438  0.000  0.000000  0.015469       0.2\n",
       "3         1.0     0.0  1.0  0.434531  0.125  0.000000  0.103644       0.2\n",
       "4         0.0     1.0  0.0  0.434531  0.000  0.000000  0.015713       0.2\n",
       "..        ...     ...  ...       ...    ...       ...       ...       ...\n",
       "886       0.0     0.5  0.0  0.334004  0.000  0.000000  0.025374       0.2\n",
       "887       1.0     0.0  1.0  0.233476  0.000  0.000000  0.058556       0.2\n",
       "888       0.0     1.0  1.0  0.334004  0.125  0.333333  0.045771       0.2\n",
       "889       1.0     0.0  0.0  0.321438  0.000  0.000000  0.058556       1.0\n",
       "890       0.0     1.0  0.0  0.396833  0.000  0.000000  0.015127       1.0\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"titanic_preprocessed.csv\", sep=\",\")\n",
    "X=np.array(df.drop(['Survived'], axis=1))\n",
    "y=np.array(df['Survived'])\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state=17)\n",
    "# normalized_data = preprocessing.normalize(df, axis=0)\n",
    "# normalized_df = pd.DataFrame(normalized_data, columns=df.columns)\n",
    "# normalized_df\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(df)\n",
    "df_scaled=pd.DataFrame(data_scaled, columns=df.columns)\n",
    "df=df_scaled      \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1= 0.5868263473053893\n",
      "f1= 0.5868263473053893\n",
      "avg= 0.5929710144927536\n"
     ]
    }
   ],
   "source": [
    "classifier_knn=KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn=classifier_knn.fit(X_train, y_train)\n",
    "predictions_knn=classifier_knn.predict(X_test)\n",
    "precission=precision_score(y_test, predictions_knn)\n",
    "recall=recall_score(y_test, predictions_knn)\n",
    "b=1\n",
    "f1_=(1+b*b)*(precission*recall)/(b*b*precission+recall)\n",
    "print(\"f1=\", f1_)\n",
    "f1=f1_score(y_test, predictions_knn)\n",
    "print(\"f1=\", f1)\n",
    "avg=(precission+recall)/2\n",
    "print(\"avg=\", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zx1hiPXxhXNp"
   },
   "source": [
    "–í –±–∏–±–ª–∏–æ—Ç–µ–∫–µ sklearn –µ—Å—Ç—å —É–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è classification_report, –≤–æ–∑–≤—Ä–∞—â–∞—é—â–∞—è precision, recall, F-–º–µ—Ä—É –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –≤ —É–¥–æ–±–Ω–æ–º –¥–ª—è —á—Ç–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–µ. –¢–∞–∫–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Ñ—É–Ω–∫—Ü–∏—è precision_recall_fscore_support, –≤–æ–∑–≤—Ä–∞—â–∞—é—â–∞—è —Ç–µ –∂–µ —Å–∞–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏, –Ω–æ –≤ —Ñ–æ—Ä–º–µ –º–∞—Å—Å–∏–≤–∞.\n",
    "\n",
    "### 2.2\n",
    "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —É—Ä–æ–∫–∞ —Ä–∞—Å—Å—á–∏—Ç–∞–π—Ç–µ –∏ –≤—ã–≤–µ–¥–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vhcIcGX5hXNq"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zUPZhuTGhXNt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6905829596412556, 0.6905829596412556, 0.6905829596412556, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75       131\n",
      "           1       0.65      0.53      0.59        92\n",
      "\n",
      "    accuracy                           0.69       223\n",
      "   macro avg       0.68      0.67      0.67       223\n",
      "weighted avg       0.69      0.69      0.68       223\n",
      "\n",
      "(0.7892376681614349, 0.7892376681614349, 0.7892376681614348, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       131\n",
      "           1       0.75      0.73      0.74        92\n",
      "\n",
      "    accuracy                           0.79       223\n",
      "   macro avg       0.78      0.78      0.78       223\n",
      "weighted avg       0.79      0.79      0.79       223\n",
      "\n",
      "(0.7982062780269058, 0.7982062780269058, 0.7982062780269058, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       131\n",
      "           1       0.78      0.72      0.75        92\n",
      "\n",
      "    accuracy                           0.80       223\n",
      "   macro avg       0.79      0.79      0.79       223\n",
      "weighted avg       0.80      0.80      0.80       223\n",
      "\n",
      "(0.7892376681614349, 0.7892376681614349, 0.7892376681614348, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       131\n",
      "           1       0.77      0.70      0.73        92\n",
      "\n",
      "    accuracy                           0.79       223\n",
      "   macro avg       0.79      0.78      0.78       223\n",
      "weighted avg       0.79      0.79      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN (K Nearest Neighbors)\n",
    "classifirer_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn=classifirer_knn.fit(X_train, y_train)\n",
    "predictions_knn=classifirer_knn.predict(X_test)\n",
    "\n",
    "rrfs_knn=precision_recall_fscore_support(y_test, predictions_knn, average='micro')\n",
    "cr_knn=classification_report(y_test, predictions_knn)\n",
    "print(rrfs_knn)\n",
    "print(cr_knn)\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "classifier_gnb=GaussianNB()\n",
    "model_gnb=classifier_gnb.fit(X_train, y_train)\n",
    "predictions_gnb=classifier_gnb.predict(X_test)\n",
    "\n",
    "rrfs_gnb=precision_recall_fscore_support(y_test, predictions_gnb, average='micro')\n",
    "cr_gnb=classification_report(y_test, predictions_gnb)\n",
    "print(rrfs_gnb)\n",
    "print(cr_gnb)\n",
    "\n",
    "# Decision Tree\n",
    "classifier_dtc=DecisionTreeClassifier(random_state=17)\n",
    "model_dtc=classifier_dtc.fit(X_train, y_train)\n",
    "predictions_dtc=classifier_dtc.predict(X_test)\n",
    "\n",
    "rrfs_dtc=precision_recall_fscore_support(y_test, predictions_dtc, average='micro')\n",
    "cr_dtc=classification_report(y_test, predictions_dtc)\n",
    "print(rrfs_dtc)\n",
    "print(cr_dtc)\n",
    "\n",
    "# Logistic regression\n",
    "classifier_lr=LogisticRegression(solver='lbfgs', random_state=17)\n",
    "model_lr=classifier_lr.fit(X_train, y_train)\n",
    "predictions_lr=classifier_lr.predict(X_test)\n",
    "\n",
    "rrfs_lr=precision_recall_fscore_support(y_test, predictions_lr, average='micro')\n",
    "cr_lr=classification_report(y_test, predictions_lr)\n",
    "print(rrfs_lr)\n",
    "print(cr_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAisAae0hXNx"
   },
   "source": [
    "–í–µ—Ä–Ω–µ–º—Å—è –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É LogisticRegression, –∫–æ—Ç–æ—Ä—ã–π –º—ã –æ–±—É—á–∞–ª–∏ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –∑–∞–¥–∞–Ω–∏–∏. –¢–∞–º –º—ã –Ω–µ –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫—É –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –º–æ–∂–Ω–æ —Å –ø–æ–º–æ—â—å—é LogisticRegressionCV - –ø–µ—Ä–µ–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Å–µ—Ç–∫–µ —Å –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π (–ø–æ —Å—É—Ç–∏ —ç—Ç–æ –∞–Ω–∞–ª–æ–≥ GridSearchCV, –Ω–æ —Å–æ —Å–≤–æ–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –≤–Ω—É—Ç—Ä–∏, –ø—Ä–∏–º–µ–Ω–∏–º—ã–º–∏ —Ç–æ–ª—å–∫–æ –∫ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏). –≠—Ç–æ—Ç –∫–ª–∞—Å—Å —Å–æ–∑–¥–∞–Ω —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏, —Ç.–∫. –¥–ª—è –Ω–µ–µ –∏–∑–≤–µ—Å—Ç–Ω—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –ø–µ—Ä–µ–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "\n",
    "–£ LogisticRegression –µ—Å—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä C - –æ–±—Ä–∞—Ç–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏. –ù–µ –≤–¥–∞–≤–∞—è—Å—å –≤ –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ —Ñ–æ—Ä–º—É–ª–µ, –º–æ–∂–Ω–æ —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ C —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç \"—Å–ª–æ–∂–Ω–æ—Å—Ç–∏\" –º–æ–¥–µ–ª–∏: —á–µ–º –±–æ–ª—å—à–µ C, —Ç–µ–º –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–æ–∂–µ—Ç –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –º–æ–¥–µ–ª—å; –µ—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä C —Å–ª–∏—à–∫–æ–º –º–∞–ª (—Å–ª–∏—à–∫–æ–º —Å–∏–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è), —Ç–æ –º–æ–¥–µ–ª—å –æ–∫–∞–∂–µ—Ç—Å—è –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π, –∞ –µ—Å–ª–∏ –Ω–∞–æ–±–æ—Ä–æ—Ç —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è —Å–ª–∏—à–∫–æ–º —Å–ª–∞–±–∞—è (—Ç.–µ. C –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –±–æ–ª—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è), —Ç–æ —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –º–æ–¥–µ–ª—å –æ–∫–∞–∂–µ—Ç—Å—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–Ω–æ–π, –ø–æ—Ç–æ–º—É –∫–∞–∫ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Å–ª–∏—à–∫–æ–º \"–±–æ—è—Ç—å—Å—è\" –æ—à–∏–±–∏—Ç—å—Å—è –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-j5LLf3hXNx"
   },
   "source": [
    "### 2.3 \n",
    "\n",
    "1. –ò—Å–ø–æ–ª—å–∑—É—è StratifiedKFold, —Ä–∞–∑–±–µ–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–æ 5-—Ç–∏ –±–ª–æ–∫–∞–º (–Ω–µ –∑–∞–±—ã–≤–∞–π—Ç–µ –≤–æ –≤—Å–µ—Ö –º–µ—Ç–æ–¥–∞—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å random_state=17).\n",
    "2. –° –ø–æ–º–æ—â—å—é numpy.logspace —Ä–∞–∑–±–µ–π—Ç–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª (-1, 2) –Ω–∞ 500 –∑–Ω–∞—á–µ–Ω–∏–π.\n",
    "3. –° –ø–æ–º–æ—â—å—é LogisticRegressionCV –ø–æ–¥–±–µ—Ä–∏—Ç–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä C: —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä Cs —Ä–∞–≤–Ω—ã–º –æ–±—ä–µ–∫—Ç—É –∏–∑ –ø.2 (—Ä–∞–∑–±–∏–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ (-1, 2) –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –ø–æ–¥–±–æ—Ä –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ C); cv —Ä–∞–≤–Ω—ã–º –æ–±—ä–µ–∫—Ç—É –∏–∑ –ø.1 (—Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏); scoring —Ä–∞–≤–Ω—ã–º \"roc_auc\" (–æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏: –º–µ—Ç—Ä–∏–∫–∞, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤ scoring, –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç, –∫–∞–∫ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –º–æ–¥–µ–ª—å –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∏–∑ –Ω–∞–±–æ—Ä–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Ç.–µ. –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∞—è –º–µ—Ç—Ä–∏–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–∞–∏–ª—É—á—à–µ–π).\n",
    "4. –û–±—É—á–∏—Ç–µ –ø–æ–ª—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0ezY2p2RhXN4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=17, shuffle=True)\n",
      "[0 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0\n",
      " 0 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0\n",
      " 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1\n",
      " 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0\n",
      " 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1\n",
      " 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1\n",
      " 0 1 0]\n",
      "0.8080808080808081\n",
      "{1: array([[0.77094972, 0.77094972, 0.77094972, ..., 0.79329609, 0.79329609,\n",
      "        0.79329609],\n",
      "       [0.7752809 , 0.7752809 , 0.7752809 , ..., 0.79213483, 0.79213483,\n",
      "        0.79213483],\n",
      "       [0.80337079, 0.80337079, 0.80337079, ..., 0.78651685, 0.78651685,\n",
      "        0.78651685],\n",
      "       [0.7752809 , 0.7752809 , 0.7752809 , ..., 0.76966292, 0.76966292,\n",
      "        0.76966292],\n",
      "       [0.83146067, 0.83146067, 0.83146067, ..., 0.82022472, 0.82022472,\n",
      "        0.82022472]])}\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=17, shuffle=True)\n",
    "s=skf.get_n_splits(X, y)\n",
    "print(skf)\n",
    "# print(len(X))\n",
    "# for train_index, test_index in skf.split(X, y):\n",
    "#     print(\"\\nTRAIN\\n:\", train_index, \"\\n\\nTEST:\\n\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "logspace_=np.logspace (start=-1, stop=2, num=500)\n",
    "clf = LogisticRegressionCV(cv=5, Cs=logspace_, random_state=17, max_iter=10000).fit(X, y)\n",
    "print(clf.predict(X))\n",
    "print(clf.score(X, y))\n",
    "print(clf.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.linear_model import LogisticRegressionCV\n",
    "# X, y = load_iris(return_X_y=True)\n",
    "# clf = LogisticRegressionCV(cv=5, random_state=17, max_iter=10000).fit(X, y)\n",
    "# print(clf.predict(X))\n",
    "# print(clf.predict_proba(X).shape)\n",
    "# print(clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7896983240223465, 0.7895393258426966, 0.7901685393258426, 0.7701348314606743, 0.8257528089887638]\n"
     ]
    }
   ],
   "source": [
    "n=np.array(clf.scores_.values)\n",
    "l=list()\n",
    "for value in clf.scores_.values():\n",
    "    for row in value:\n",
    "        avg=np.average(row)\n",
    "        l.append(avg)\n",
    "print(l)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework_classification-2_les-1_part-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
